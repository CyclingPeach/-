{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前置准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import asyncio\n",
    "import traceback\n",
    "import aiohttp\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import pymongo\n",
    "from lxml import etree\n",
    "from parsel import Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MongoDB 连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(host='localhost', port=27017)\n",
    "db = client['indianhospital']\n",
    "\n",
    "province_col          = db['province']\n",
    "hospital_col          = db['hospital']\n",
    "all_page_col          = db['all_page']\n",
    "hospital_detail_info  = db['hospital_detail_info']\n",
    "\n",
    "# error_province_col = db['error_province']\n",
    "# error_hospital_col = db['error_hospital']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 请求头 & 随机代理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://89.163.210.203:3128', {'http': 'http://89.208.219.121:8080'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# headers = {\n",
    "#     'sec-ch-ua' : '\"Google Chrome\";v=\"105\", \"Not)A;Brand\";v=\"8\", \"Chromium\";v=\"105\"',\n",
    "#     'sec-ch-ua-mobile'  : '?0',\n",
    "#     'sec-ch-ua-platform': '\"Windows\"',\n",
    "#     'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'\n",
    "# }\n",
    "\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "def random_proxy():\n",
    "    proxy = 'http://' + requests.get('http://127.0.0.1:5555/random').text.strip()\n",
    "    return proxy\n",
    "\n",
    "def random_proxies():\n",
    "    proxies = {\n",
    "        'http' : 'http://' + requests.get('http://127.0.0.1:5555/random').text.strip()\n",
    "    }\n",
    "    return proxies\n",
    "random_proxy(), random_proxies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正式采集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取 37 个省的信息\n",
    "\n",
    "- 包含：名字、链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "一、获取 37 个省份的链接\n",
    "返回一个包含 37 个省份链接的列表\n",
    "\"\"\"\n",
    "origin_url = 'https://www.medindia.net/patients/hospital_search/hospital_list.asp?utm_source=topnavigation&utm_medium=desktop&utm_content=&utm_campaign=medindia'\n",
    "try:\n",
    "    origin_res = requests.get(\n",
    "        url     = origin_url,\n",
    "        headers = headers,\n",
    "        proxies = random_proxies()\n",
    "    )\n",
    "    selector = Selector(text = origin_res.text)\n",
    "\n",
    "    for div in selector.xpath('//ul[@class=\"list-inline\"]/div/div'):\n",
    "        province_name = div.xpath('./li/a/span/text()').get().title()   # 所有单词首字母大写\n",
    "        province_href = div.xpath('./li/a/@href').get()\n",
    "        if province_col.find_one({'province_name':province_name}) != None:\n",
    "            continue\n",
    "        else:\n",
    "            province_col.insert_one({\n",
    "                'province_name'  :province_name,\n",
    "                'province_href'  :province_href,\n",
    "                'province_status':None\n",
    "            })\n",
    "    print('【SUCCEED -- CRAWL PROVINCE SUCCEED】')\n",
    "except:\n",
    "    print('【ERROR   -- CRAWL PROVINCE FAILED 】')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 采集医院包含的所有页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "province_status_list = []\n",
    "\n",
    "for province in province_col.find():\n",
    "    province_name   = province['province_name']\n",
    "    province_href   = province['province_href']\n",
    "    province_status = province['province_status']\n",
    "    # 先判断是否已经采集过某省的医院了\n",
    "    if province_status == 1:    # 如果 1        跳过该省\n",
    "        continue\n",
    "    else:                       # 如果 0 / None 采集该省的页\n",
    "        try:\n",
    "            selector = Selector(text = requests.get(province_href, headers=headers, proxies=random_proxies()).text)\n",
    "            records  = int(selector.xpath('//p[@class=\"searchtext\"][contains(text(), \"Total Records\")]/b[1]/text()').get())\n",
    "            page     = int(selector.xpath('//p[@class=\"searchtext\"][contains(text(), \"Total Records\")]/b[last()]/text()').get())\n",
    "            if records <= 25:   # 如果该省总医院记录（records）小于 25，则该省总页数只有 1 页\n",
    "                total_page_of_province = 1\n",
    "            else:\n",
    "                total_page_of_province = page\n",
    "            total_page_href_of_province = [province_href[:-4] + f'-{str(i)}' + province_href[-4:] for i in range(1, total_page_of_province+1)]\n",
    "            for href in total_page_href_of_province:\n",
    "                all_page_col.insert_one({\n",
    "                    'province_name'          : province_name,\n",
    "                    'page_of_province'       : href,\n",
    "                    'page_of_province_status': None,\n",
    "                })\n",
    "            province_status_list.append({'province_name':province_name,'province_new_status':1})\n",
    "        except Exception as e:\n",
    "            print('错误类型是',e.__class__.__name__)\n",
    "            print('错误明细是',e)\n",
    "            province_status_list.append({'province_name':province_name,'province_new_status':0})\n",
    "\n",
    "# 统一 province_col 数据库的状态\n",
    "for province in province_status_list:\n",
    "    condition        = {'province_name':province['province_name']}\n",
    "    update_status    = province_col.find_one(condition)\n",
    "    update_status['province_status']  = province['province_new_status']\n",
    "    province_col.update_one(condition,{'$set': update_status})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 采集每页的医院链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|----|【PAGE】——Start Page Hospitals-Telangana\n",
      "|----|【PAGE】——Start Page Hospitals-Tripura\n"
     ]
    }
   ],
   "source": [
    "for province in province_col.find():\n",
    "    province_name = province['province_name']\n",
    "    if province['province_status'] != 1:    \n",
    "        # 如果状态为 0 / Null —— 说明没有这个省的数据（页），就不采集其医院信息\n",
    "        continue\n",
    "    else:           \n",
    "        # 省的状态为 1 —— 采集该省的信息\n",
    "        # print(f'|【PROVINCE】——Start Province {province_name}')\n",
    "        for page in all_page_col.find({'province_name':province_name}):\n",
    "            page_of_province        = page['page_of_province']\n",
    "            page_of_province_status = page['page_of_province_status']\n",
    "            # 更新用\n",
    "            condition   = {'page_of_province':page_of_province}\n",
    "            update_page = all_page_col.find_one(condition)\n",
    "\n",
    "            if page_of_province_status == 1:    # 该页的状态为 1 —— 说明已经采集过了，跳过不采集\n",
    "                continue\n",
    "            else:                               # 该页的状态为 0 / None —— 采集\n",
    "                print('|----|【PAGE】——Start Page', re.search('hospital_search/(.*?).htm', page_of_province).group(1).title())\n",
    "                try:\n",
    "                    page_res = requests.get(\n",
    "                        url     = page_of_province, \n",
    "                        headers = headers, \n",
    "                        proxies = random_proxies()\n",
    "                    )\n",
    "                    selector = Selector(text = page_res.text)\n",
    "                    # 这个爬虫逻辑似乎有问题，会多爬一些信息\n",
    "                    hospital_list = selector.xpath('//div[@class=\"dr-lists\"][1]//h3[@class=\"vert-small-margin\"]/a')\n",
    "                    for hospital in hospital_list:\n",
    "                        hospital_belong_province = province_name\n",
    "                        hospital_name   = hospital.xpath('./text()').re_first('(\\w+.*?),').title()\n",
    "                        hospital_href   = hospital.xpath('./@href').get()\n",
    "                        hospital_status = None\n",
    "                        hospital_col.insert_one({\n",
    "                            'hospital_belong_province':hospital_belong_province,\n",
    "                            'hospital_name'  :hospital_name,\n",
    "                            'hospital_href'  :hospital_href,\n",
    "                            'hospital_status':hospital_status,\n",
    "                        })\n",
    "                    # 更新页状态\n",
    "                    update_page['page_of_province_status'] = 1\n",
    "                    all_page_col.update_one(condition, {'$set':update_page})\n",
    "                    # print(f'|----|----|【SCRAW PAGE SUCCEED】{page_of_province}')\n",
    "                except Exception as e:\n",
    "                    # 更新页状态\n",
    "                    update_page['page_of_province_status'] = 0\n",
    "                    all_page_col.update_one(condition, {'$set':update_page})\n",
    "                    print(f'|----|----|⭕【SCRAW PAGE ERROR】{page_of_province}')\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "        # print(f'|✅ {province_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 采集医院的详细信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hospital_name = selector.xpath('//div[@class=\"mi-bg-1\"]/../h2/text()').re_first('Address of (.*)')\n",
    "# hospital_address       = ', '.join(selector.xpath('//div[@class=\"mi-bg-1\"]/div/div/div[contains(@class, \"report-content\")]/p[1]//text()').re('\\s*(\\w.*\\w)\\s*,*'))\n",
    "# hospital_director      = selector.xpath('//div[@class=\"mi-bg-1\"]/div/div/div[contains(@class, \"report-content\")]/p/b[contains(text(), \"Director\")]/../text()').re_first('\\s*(\\w.*\\w)\\s*')\n",
    "# hospital_email         = selector.xpath('//div[@class=\"mi-bg-1\"]/div/div/div[contains(@class, \"report-content\")]/p/b[contains(text(), \"Email\")]/../span/text()').re_first('\\s*(\\w.*\\w)\\s*')\n",
    "# hospital_phone         = selector.xpath('//div[@class=\"mi-bg-1\"]/div/div/div[contains(@class, \"report-content\")]/p/b[contains(text(), \"Phone\")]/../span/text()').re_first('\\s*(\\w.*\\w)\\s*')\n",
    "# hospital_mobile        = selector.xpath('//div[@class=\"mi-bg-1\"]/div/div/div[contains(@class, \"report-content\")]/p/b[contains(text(), \"Mobile\")]/../span/text()').re_first('\\s*(\\w.*\\s)\\s*')\n",
    "\n",
    "# hospital_detail_info = {\n",
    "#     'hospital_name'    : hospital_name,\n",
    "#     'hospital_address' : hospital_address,\n",
    "#     'hospital_director': hospital_director,\n",
    "#     'hospital_email'   : hospital_email,\n",
    "#     'hospital_phone'   : hospital_phone,\n",
    "#     'hospital_mobile'  : hospital_mobile,\n",
    "#     'hospital_href' : None,\n",
    "#     'hospital_html' : None,\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 详细信息采集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://45.152.188.62:3128 {'http': 'http://114.116.2.116:8001'}\n"
     ]
    }
   ],
   "source": [
    "### 导库\n",
    "import re\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import traceback\n",
    "import pymongo\n",
    "from lxml import etree\n",
    "from parsel import Selector\n",
    "\n",
    "\n",
    "\n",
    "### UA & 随机代理\n",
    "# headers = {\n",
    "#     'sec-ch-ua' : '\"Google Chrome\";v=\"105\", \"Not)A;Brand\";v=\"8\", \"Chromium\";v=\"105\"',\n",
    "#     'sec-ch-ua-mobile'  : '?0',\n",
    "#     'sec-ch-ua-platform': '\"Windows\"',\n",
    "#     'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'\n",
    "# }\n",
    "\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "def random_proxy():\n",
    "    proxy = 'http://' + requests.get('http://127.0.0.1:5555/random').text.strip()\n",
    "    return proxy\n",
    "\n",
    "def random_proxies():\n",
    "    proxies = {\n",
    "        'http' : 'http://' + requests.get('http://127.0.0.1:5555/random').text.strip()\n",
    "    }\n",
    "    return proxies\n",
    "print(random_proxy(), random_proxies())\n",
    "\n",
    "\n",
    "\n",
    "### MongoDB连接\n",
    "client = pymongo.MongoClient(host='localhost', port=27017)\n",
    "db = client['indianhospital']\n",
    "\n",
    "province_col              = db['province']\n",
    "all_page_col              = db['all_page']\n",
    "hospital_col              = db['hospital']\n",
    "hospital_detail_info_col  = db['hospital_detail_info']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 采集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.medindia.net/patients/hospital_search/chakraborty-hospital-port-blair-andaman-nicobar-95591-1.htm',\n",
       " 'https://www.medindia.net/patients/hospital_search/chakraborty-multi-speciality-hospital-south-andaman-andaman-and-nicobar-islands-14966-1.htm',\n",
       " 'https://www.medindia.net/patients/hospital_search/dragarwals-eye-hospital-port-blair-andaman-nicobar-68192-1.htm',\n",
       " 'https://www.medindia.net/patients/hospital_search/inhs-dhanvantri-south-andaman-andaman-and-nicobar-islands-21526-1.htm',\n",
       " 'https://www.medindia.net/patients/hospital_search/maricar-hospital-port-blair-andaman-and-nicobar-islands-25782-1.htm',\n",
       " 'https://www.medindia.net/patients/hospital_search/pillar-health-centre-port-blair-andaman-and-nicobar-islands-26347-1.htm',\n",
       " 'https://www.medindia.net/patients/hospital_search/welcare-ayurvedic-hospital-port-blair-andaman-nicobar-39346-1.htm',\n",
       " 'https://www.medindia.net/patients/hospital_search/modern-eye-hospital-research-centre-nellore-andhra-pradesh-25693-1.htm',\n",
       " 'https://www.medindia.net/patients/hospital_search/radha-krishna-nursing-home-vizianagaram-andhra-pradesh-26957-1.htm',\n",
       " 'https://www.medindia.net/patients/hospital_search/rainbow-childrens-hospital-vijayawada-andhra-pradesh-27181-1.htm']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set  = hospital_col.find()[:10]\n",
    "href_list = []\n",
    "for each in test_set:\n",
    "    href_list.append(each['hospital_href'])\n",
    "href_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for href in href_list:\n",
    "    try:\n",
    "        res = requests.get(href, proxies=random_proxies(), headers=headers)\n",
    "        print(res.status_code)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://140.250.89.243:20217\n",
      "http://140.250.144.157:17514\n",
      "http://125.106.131.203:23269\n",
      "http://113.239.22.225:18267\n",
      "http://36.6.159.21:23712\n",
      "http://36.6.159.21:23712\n",
      "http://114.237.61.80:19882\n",
      "http://114.237.61.80:19882\n",
      "http://60.168.207.71:17507\n",
      "http://36.6.159.21:23712\n",
      "Cannot connect to host 125.106.131.203:23269 ssl:default [Connect call failed ('125.106.131.203', 23269)]\n",
      "--------------------------------------------------\n",
      "Cannot connect to host 140.250.89.243:20217 ssl:default [Connect call failed ('140.250.89.243', 20217)]\n",
      "--------------------------------------------------\n",
      "Cannot connect to host 60.168.207.71:17507 ssl:default [Connect call failed ('60.168.207.71', 17507)]\n",
      "--------------------------------------------------\n",
      "Cannot connect to host 113.239.22.225:18267 ssl:default [Connect call failed ('113.239.22.225', 18267)]\n",
      "--------------------------------------------------\n",
      "Cannot connect to host 140.250.144.157:17514 ssl:default [Connect call failed ('140.250.144.157', 17514)]\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def get_status(href):\n",
    "    timeout = aiohttp.ClientTimeout(total = 10 )   # 超时设置\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            proxy = random.choice(proxy_list)\n",
    "            print(proxy)\n",
    "            async with session.get(url=href, proxy=proxy, headers=headers, timeout=timeout) as res:\n",
    "                if res.status == 200:\n",
    "                    print('PASS')\n",
    "                    # html = await res.text()\n",
    "                    # print(json.loads(html)['origin'])\n",
    "        except Exception as e:\n",
    "            # print(traceback.print_exc())\n",
    "            print(e)\n",
    "            pass\n",
    "        print('-'*50)\n",
    "\n",
    "def main():\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = [get_status(href) for href in href_list]\n",
    "    # tasks = [get_status('http://httpbin.org/get') for i in range(100)]\n",
    "    loop.run_until_complete(asyncio.wait(tasks))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://114.237.61.80:19882'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iplist = [\n",
    "    '36.6.159.21:23712',\n",
    "    '140.250.144.157:17514',\n",
    "    '183.143.61.223:18695',\n",
    "    '112.66.244.193:22511',\n",
    "    '125.106.131.203:23269',\n",
    "    '140.250.89.243:20217',\n",
    "    '114.237.61.80:19882',\n",
    "    '113.239.22.225:18267',\n",
    "    '60.168.207.71:17507',\n",
    "    '58.52.48.39:21822',\n",
    "]\n",
    "proxy_list   = []\n",
    "proxies_list = []\n",
    "for ip in iplist:\n",
    "    proxies = {\n",
    "        'http' : 'http://'+ip,\n",
    "        'https': 'https://'+ip\n",
    "    }\n",
    "    proxy = 'http://'+ip\n",
    "    proxies_list.append(proxies)\n",
    "    proxy_list.append(proxy)\n",
    "\n",
    "random.choice(proxy_list)\n",
    "random.choice(proxies_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7a2c57dd8fa1beacd4b54a192872601175e26d7f310ef80f9ea3a51d91ad3bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
